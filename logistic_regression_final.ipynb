{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c0bf35",
   "metadata": {},
   "source": [
    "# Q) As threshold approaches 0.5, accuracy increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f70543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "epoch=100\n",
    "\n",
    "lr_=[0.01,0.001,0.0001]\n",
    "threshold_=[0.5,0.3,0.4,0.6,0.7]\n",
    "\n",
    "\n",
    "#stores all possible values of accuracy, precision and recall\n",
    "\n",
    "l1=[[],[],[],[],[],[],[],[],[],[]] \n",
    "l2=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l3=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l4=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l5=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l6=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l7=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l8=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l9=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l10=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l11=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l12=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l13=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l14=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l15=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l16=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l17=[[],[],[],[],[],[],[],[],[],[]]\n",
    "l18=[[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    y=1/(1+np.exp(-x))\n",
    "    return y\n",
    "\n",
    "def nll_grad(x_train,y_train,w,bias):\n",
    "    del_w=np.zeros(30)\n",
    "    del_bias=0\n",
    "    columns=len(x_train[0])\n",
    "    rows=len(x_train)\n",
    "    \n",
    "    for i in range(columns):\n",
    "        k=0        \n",
    "        del_bias=0\n",
    "        for j in range(rows):\n",
    "            y_predicted=sigmoid(np.dot(w,x_train[j])+bias)\n",
    "            k=k+((y_predicted-y_train[j])*x_train[j][i])    \n",
    "            del_bias += (sigmoid(np.dot(w,x_train[j]))-y_train[j])/rows\n",
    "   \n",
    "        del_w[i]=k/rows\n",
    "        \n",
    "    return del_w,del_bias\n",
    "\n",
    "\n",
    "def grad_desc(epoch, lr,x_train,y_train,threshold):\n",
    "    w=np.zeros(30)\n",
    "    bias=0\n",
    "    nll=[]\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        del_w,del_bias=nll_grad(x_train,y_train,w,bias)\n",
    "        w=w-lr*del_w\n",
    "        bias=bias-lr*del_bias\n",
    "        n=0\n",
    "        for m in range(len(x_train)):\n",
    "            yn=sigmoid(np.dot(w,x_train[m])+bias)\n",
    "            n=n+ ((y_train[m]*(yn))+(1-y_train[m])*(1-yn))\n",
    "        nll.append(-n)\n",
    "        \n",
    "    x_points=range(1,len(nll)+1)\n",
    "    s=\"Batch Gradient Descent Lr = \"+ str(lr) + \" Threshold = \" + str(threshold)\n",
    "    plt.plot(x_points,nll)\n",
    "    plt.xlabel('Iterations', fontsize=20)\n",
    "    plt.ylabel('NLL ', fontsize=20)\n",
    "    plt.title(s)\n",
    "    plt.show()\n",
    "    return w,bias\n",
    "\n",
    "def predict(x_test,w,bias,threshold):\n",
    "    y_predict=np.zeros(len(x_test))\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        prob=sigmoid(np.dot(w,x_test[i])+bias)\n",
    "        \n",
    "\n",
    "        \n",
    "        if prob>=threshold:\n",
    "            y_predict[i]=1\n",
    "        else:\n",
    "            y_predict[i]=0\n",
    "    return y_predict\n",
    "\n",
    "def confusion_matrix(y_predict,y_test):\n",
    "    confusion=np.zeros((2,2))\n",
    "    tn=tp=fn=fp=0\n",
    "    \n",
    "    accuracy=precision = 0\n",
    "    \n",
    "    for i in range(len(y_predict)):\n",
    "        if y_predict[i]==0 and y_test[i]==0:\n",
    "            tn+=1\n",
    "        elif  y_predict[i]==1 and y_test[i]==1:\n",
    "            tp+=1\n",
    "        elif  y_predict[i]==0 and y_test[i]==1:\n",
    "            fn+=1\n",
    "        elif  y_predict[i]==1 and y_test[i]==0:\n",
    "            fp+=1\n",
    "    confusion[0,0]=tn \n",
    "    confusion[0,1]=fp\n",
    "    confusion[1,0]=fn\n",
    "    confusion[1,1]=tp\n",
    "    accuracy=(tp+tn)/len(y_predict)\n",
    "    if (tp+fp) != 0:\n",
    "        precision=tp/(tp+fp)\n",
    "    \n",
    "    if (tp+fn)!=0:\n",
    "        recall=tp/(tp+fn)\n",
    "    \n",
    "    \n",
    "    return confusion, accuracy, precision, recall\n",
    "                \n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------------------  \n",
    "    \n",
    "    \n",
    "for itr in range(10):\n",
    "    print(\"ITERATION :\", itr+1)\n",
    "    \n",
    "    df = pd.read_csv('Data set.csv')\n",
    "    df.drop(columns='id',axis=1,inplace=True)   #dropping column id as it might give incorrect correlations\n",
    "\n",
    "\n",
    "\n",
    "    for col in df.columns:        #labelling benign as 0 and malignant as 1\n",
    "        if col== 'diagnosis':\n",
    "            df.loc[df[col]== 'M',col]= 1 #benign =0 ,malignant=1\n",
    "            df.loc[df[col]== 'B',col] = 0\n",
    "\n",
    "    df = df.sample(frac=1) #shuffles the rows \n",
    "    \n",
    "    #batch gradient descent LR1 - df, LR2 - df2\n",
    "    #stochastic gradient descent LR1 - df3 , LR2 - df4\n",
    "    #mini batch gradient descent LR1 - df5, LR2 - df6\n",
    "      \n",
    "    df2=df   \n",
    "    df4=df\n",
    "    df6=df\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    df3=df  #df, df3, df5 have NaN values dropped as Feature Engr 1 is not applied to LR1 models\n",
    "    df5=df\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    for threshold in threshold_:  \n",
    "        for lr in lr_:\n",
    "            \n",
    "            #batch gradient descent LR1\n",
    " \n",
    "            ratio = 0.67\n",
    "            total_rows = df.shape[0]\n",
    "            train_size = int(total_rows*ratio)\n",
    "            train = df[0:train_size]\n",
    "            test = df[train_size:]\n",
    "\n",
    "            target='diagnosis'\n",
    "            y_train=train[target]\n",
    "            y_test=test[target]\n",
    "            y_train=y_train.astype('int')\n",
    "            y_test=y_test.astype('int')\n",
    "            train.drop(columns=target,axis=1,inplace=True)\n",
    "            test.drop(columns=target,axis=1,inplace=True)\n",
    "            x_train=train\n",
    "            x_test=test\n",
    "\n",
    "            #converting to numpy arrays\n",
    "            x_train=np.array(x_train)\n",
    "            x_test=np.array(x_test)\n",
    "            y_train=np.array(y_train)\n",
    "            y_test=np.array(y_test)\n",
    "\n",
    "\n",
    "\n",
    "            w,bias=grad_desc(epoch,lr,x_train,y_train,threshold)\n",
    "\n",
    "\n",
    "            y_predict=predict(x_test,w,bias,threshold)\n",
    "\n",
    "\n",
    "            confusion, accuracy, precision, recall= confusion_matrix(y_predict,y_test)\n",
    "            print(\"CONFUSION MATRIX\")\n",
    "            print(confusion)\n",
    "            print(\"ACCURACY =\", accuracy)\n",
    "            print(\"PRECISION =\", precision)\n",
    "            print(\"RECALL =\", recall)\n",
    "            print(\"\")\n",
    "            \n",
    "            l1[itr].append(accuracy)\n",
    "            l2[itr].append(precision)\n",
    "            l3[itr].append(recall)           \n",
    "            \n",
    "\n",
    "\n",
    "            #---------------------------------------------------------------------------------------------------------------------------  \n",
    "            \n",
    "            #Batch gradient descent LR2\n",
    "            \n",
    "            \n",
    "            for col in df2.columns:    #filling in the missing values with the mean of that column\n",
    "                if col!= 'diagnosis':\n",
    "                    mean=df2[col].mean()\n",
    "                    df2[col] = df2[col].fillna(mean)\n",
    "                else:\n",
    "                    df2.loc[df2[col]== 'M',col]= 1 #benign =0 ,malignant=1\n",
    "                    df2.loc[df2[col]== 'B',col] = 0\n",
    "            for column in df2.columns:   #normalization\n",
    "                if column != 'id' and column!= 'diagnosis':\n",
    "                    df2[column] = (df2[column] - df2[column].mean()) / df2[column].std()\n",
    "\n",
    "\n",
    "            ratio = 0.67\n",
    "            total_rows = df2.shape[0]\n",
    "            train_size = int(total_rows*ratio)\n",
    "            train = df2[0:train_size]\n",
    "            test = df2[train_size:]    \n",
    "\n",
    "\n",
    "            target='diagnosis'\n",
    "            y_train=train[target]\n",
    "            y_test=test[target]\n",
    "            y_train=y_train.astype('int')\n",
    "            y_test=y_test.astype('int')\n",
    "            train.drop(columns=target,axis=1,inplace=True)\n",
    "            test.drop(columns=target,axis=1,inplace=True)\n",
    "            x_train=train\n",
    "            x_test=test\n",
    "\n",
    "\n",
    "            x_train=np.array(x_train)\n",
    "            x_test=np.array(x_test)\n",
    "            y_train=np.array(y_train)\n",
    "            y_test=np.array(y_test)\n",
    "\n",
    "\n",
    "\n",
    "            w,bias=grad_desc(epoch,lr,x_train,y_train,threshold)\n",
    "\n",
    "            y_predict=predict(x_test,w,bias,threshold)\n",
    "\n",
    "            confusion, accuracy, precision, recall= confusion_matrix(y_predict,y_test)\n",
    "            print(\"CONFUSION MATRIX\")\n",
    "            print(confusion)\n",
    "            print(\"ACCURACY =\", accuracy)\n",
    "            print(\"PRECISION =\", precision)\n",
    "            print(\"RECALL =\", recall)\n",
    "            print(\"\")\n",
    "            \n",
    "            l4[itr].append(accuracy)\n",
    "            l5[itr].append(precision)\n",
    "            l6[itr].append(recall)\n",
    "            \n",
    "\n",
    "\n",
    "            #---------------------------------------------------------------------------------------------------------------------------  \n",
    "\n",
    "\n",
    "            #stochastic gradient descent LR1\n",
    "\n",
    "            df3 = df3.dropna()\n",
    "            df3 = df3.reset_index(drop=True)\n",
    "\n",
    "            ratio = 0.67\n",
    "            total_rows = df3.shape[0]\n",
    "            train_size = int(total_rows*ratio)\n",
    "            train = df3[0:train_size]\n",
    "            test = df3[train_size:]\n",
    "\n",
    "            target='diagnosis'\n",
    "            y_train=train[target]\n",
    "            y_test=test[target]\n",
    "            y_train=y_train.astype('int')\n",
    "            y_test=y_test.astype('int')\n",
    "            train.drop(columns=target,axis=1,inplace=True)\n",
    "            test.drop(columns=target,axis=1,inplace=True)\n",
    "            x_train=train\n",
    "            x_test=test\n",
    "\n",
    "            #converting to numpy arrays\n",
    "            x_train=np.array(x_train)\n",
    "            x_test=np.array(x_test)\n",
    "            y_train=np.array(y_train)\n",
    "            y_test=np.array(y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            def stochastic_desc(epoch,x_train,y_train,lr,threshold):\n",
    "                w=np.zeros(30)\n",
    "                bias=0\n",
    "                c=epoch*len(x_train)\n",
    "                nll=np.zeros(c) \n",
    "                x_points=np.array(range(1,c+1))\n",
    "                c=0\n",
    "                for i in range (epoch):\n",
    "                    for j in range(len(x_train)):\n",
    "                        del_w=np.zeros(30)\n",
    "                        del_bias=0\n",
    "\n",
    "                        columns=len(x_train[j])\n",
    "\n",
    "                        for k in range(columns):\n",
    "                            yn=sigmoid(np.dot(w,x_train[j])+bias)\n",
    "\n",
    "                            del_w[k]=((yn-y_train[j])*x_train[j][k])            \n",
    "\n",
    "                        del_bias += (sigmoid(np.dot(w,x_train[j]))-y_train[j])\n",
    "\n",
    "                        w=w-lr*del_w\n",
    "                        bias=bias-lr*del_bias\n",
    "\n",
    "                        nll[c]=y_train[j]*sigmoid(np.dot(w,x_train[j])+bias) + (1-y_train[j])*(1-sigmoid(np.dot(w,x_train[j])+bias))\n",
    "                        c=c+1\n",
    "                x_points=np.array(range(1,len(nll)+1))\n",
    "                s=\"Stochastic Gradient Descent Lr = \"+ str(lr) + \" Threshold = \" + str(threshold)\n",
    "                plt.plot(x_points,nll)\n",
    "                plt.xlabel('Iterations', fontsize=20)\n",
    "                plt.ylabel('NLL ', fontsize=20)\n",
    "                plt.title(s)\n",
    "                plt.show()\n",
    "\n",
    "                return w,bias\n",
    "\n",
    "\n",
    "            w,bias=stochastic_desc(epoch,x_train,y_train,lr,threshold)\n",
    "\n",
    "            y_predict=predict(x_test,w,bias,threshold)\n",
    "\n",
    "            confusion, accuracy, precision, recall= confusion_matrix(y_predict,y_test)\n",
    "            print(\"CONFUSION MATRIX \\n\")\n",
    "            print(confusion)\n",
    "            print(\"ACCURACY =\", accuracy)\n",
    "            print(\"PRECISION =\", precision)\n",
    "            print(\"RECALL =\", recall)\n",
    "            print(\"\")\n",
    "            \n",
    "            l7[itr].append(accuracy)\n",
    "            l8[itr].append(precision)\n",
    "            l9[itr].append(recall)\n",
    "            \n",
    "            \n",
    "            #---------------------------------------------------------------------------------------------------------------------------  \n",
    "\n",
    "            #stochastic gradient descent LR2\n",
    "            \n",
    "            \n",
    "            for col in df4.columns:    #filling in the missing values with the mean of that column\n",
    "                if col!= 'diagnosis':\n",
    "                    mean=df4[col].mean()\n",
    "                    df4[col] = df4[col].fillna(mean)\n",
    "                else:\n",
    "                    df4.loc[df4[col]== 'M',col]= 1 #benign =0 ,malignant=1\n",
    "                    df4.loc[df4[col]== 'B',col] = 0\n",
    "            for column in df4.columns:   #normalization\n",
    "                if column != 'id' and column!= 'diagnosis':\n",
    "                    df4[column] = (df4[column] - df4[column].mean()) / df4[column].std()\n",
    "\n",
    "\n",
    "            ratio = 0.67\n",
    "            total_rows = df4.shape[0]\n",
    "            train_size = int(total_rows*ratio)\n",
    "            train = df4[0:train_size]\n",
    "            test = df4[train_size:]    \n",
    "\n",
    "\n",
    "            target='diagnosis'\n",
    "            y_train=train[target]\n",
    "            y_test=test[target]\n",
    "            y_train=y_train.astype('int')\n",
    "            y_test=y_test.astype('int')\n",
    "            train.drop(columns=target,axis=1,inplace=True)\n",
    "            test.drop(columns=target,axis=1,inplace=True)\n",
    "            x_train=train\n",
    "            x_test=test\n",
    "\n",
    "\n",
    "            x_train=np.array(x_train)\n",
    "            x_test=np.array(x_test)\n",
    "            y_train=np.array(y_train)\n",
    "            y_test=np.array(y_test)\n",
    "\n",
    "            w,bias=stochastic_desc(epoch,x_train,y_train,lr,threshold)\n",
    "\n",
    "            y_predict=predict(x_test,w,bias,threshold)\n",
    "\n",
    "\n",
    "            confusion, accuracy, precision, recall= confusion_matrix(y_predict,y_test)\n",
    "            print(\"CONFUSION MATRIX \\n\")\n",
    "            print(confusion)\n",
    "            print(\"ACCURACY =\", accuracy)\n",
    "            print(\"PRECISION =\", precision)\n",
    "            print(\"RECALL =\", recall)\n",
    "            print(\"\")\n",
    "            \n",
    "            l10[itr].append(accuracy)\n",
    "            l11[itr].append(precision)\n",
    "            l12[itr].append(recall)\n",
    "\n",
    "\n",
    "\n",
    "           #---------------------------------------------------------------------------------------------------------------------------  \n",
    "\n",
    "\n",
    "            #mini batch gradient descent LR1\n",
    "\n",
    "\n",
    "            df5 = df5.dropna()\n",
    "            df5 = df5.reset_index(drop=True)\n",
    "\n",
    "            ratio = 0.67\n",
    "            total_rows = df5.shape[0]\n",
    "            train_size = int(total_rows*ratio)\n",
    "            train = df5[0:train_size]\n",
    "            test = df5[train_size:]\n",
    "\n",
    "            target='diagnosis'\n",
    "            y_train=train[target]\n",
    "            y_test=test[target]\n",
    "            y_train=y_train.astype('int')\n",
    "            y_test=y_test.astype('int')\n",
    "            train.drop(columns=target,axis=1,inplace=True)\n",
    "            test.drop(columns=target,axis=1,inplace=True)\n",
    "            x_train=train\n",
    "            x_test=test\n",
    "\n",
    "            #converting to numpy arrays\n",
    "            x_train=np.array(x_train)\n",
    "            x_test=np.array(x_test)\n",
    "            y_train=np.array(y_train)\n",
    "            y_test=np.array(y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            batch = 10\n",
    "            c=int(np.floor((len(x_train))/batch))\n",
    "\n",
    "            def mini_batch_desc(x_train,y_train,batch):\n",
    "                w=np.zeros(30)\n",
    "                bias=0\n",
    "                nll=[]\n",
    "                for i in range(epoch):\n",
    "\n",
    "                    for j in range(c):\n",
    "\n",
    "\n",
    "                        batch_x=x_train[j* batch : ((j+1) * batch),:]\n",
    "                        batch_y=y_train[j* batch : ((j+1) * batch)]\n",
    "\n",
    "                        del_w=np.zeros(30)\n",
    "                        del_bias=0\n",
    "                        columns=30\n",
    "                        rows=len(batch_x)\n",
    "\n",
    "                        for b in range(columns):\n",
    "                            k=0        \n",
    "                            del_bias=0\n",
    "                            for j in range(rows):\n",
    "                                y_predicted=sigmoid(np.dot(w,batch_x[j])+bias)\n",
    "                                k=k+((y_predicted-batch_y[j])*batch_x[j][b])    \n",
    "                                del_bias += (sigmoid(np.dot(w,batch_x[j]))-batch_y[j])/rows\n",
    "\n",
    "                            del_w[b]=k/rows\n",
    "\n",
    "                        w=w-(lr*del_w)\n",
    "                        bias=bias- (lr*del_bias)\n",
    "\n",
    "                        n=0\n",
    "                        for m in range(len(batch_x)):\n",
    "                            yn=sigmoid(np.dot(w,batch_x[m])+bias)\n",
    "                            n=n+ ((batch_y[m]*(yn))+(1-batch_y[m])*(1-yn))\n",
    "                        nll.append(-n)\n",
    "                return w, bias, nll\n",
    "\n",
    "            w,bias,nll=mini_batch_desc(x_train,y_train,batch)\n",
    "            y_predict=predict(x_test,w,bias,threshold)\n",
    "\n",
    "            x_points=range(1,len(nll)+1)\n",
    "            s=\"Mini Batch Gradient Lr = \"+ str(lr) + \" Threshold = \" + str(threshold)\n",
    "            plt.plot(x_points,nll)\n",
    "            plt.xlabel('Iterations', fontsize=20)\n",
    "            plt.ylabel('NLL ', fontsize=20)\n",
    "            plt.title(s)\n",
    "            plt.show()\n",
    "\n",
    "            confusion, accuracy, precision, recall= confusion_matrix(y_predict,y_test)\n",
    "            print(\"CONFUSION MATRIX \\n\")\n",
    "            print(confusion)\n",
    "            print(\"ACCURACY =\", accuracy)\n",
    "            print(\"PRECISION =\", precision)\n",
    "            print(\"RECALL =\", recall)\n",
    "            print(\"\")\n",
    "            \n",
    "            l13[itr].append(accuracy)\n",
    "            l14[itr].append(precision)\n",
    "            l15[itr].append(recall)            \n",
    "\n",
    "\n",
    "            #---------------------------------------------------------------------------------------------------------------------------  \n",
    "            \n",
    "            #mini batch gradient descent LR2\n",
    "            \n",
    "            \n",
    "            for col in df6.columns:    #filling in the missing values with the mean of that column\n",
    "                if col!= 'diagnosis':\n",
    "                    mean=df6[col].mean()\n",
    "                    df6[col] = df6[col].fillna(mean)\n",
    "                else:\n",
    "                    df6.loc[df6[col]== 'M',col]= 1 #benign =0 ,malignant=1\n",
    "                    df6.loc[df6[col]== 'B',col] = 0\n",
    "            for column in df6.columns:   #normalization\n",
    "                if column != 'id' and column!= 'diagnosis':\n",
    "                    df6[column] = (df6[column] - df6[column].mean()) / df6[column].std()\n",
    "\n",
    "\n",
    "            ratio = 0.67\n",
    "            total_rows = df6.shape[0]\n",
    "            train_size = int(total_rows*ratio)\n",
    "            train = df6[0:train_size]\n",
    "            test = df6[train_size:]    \n",
    "\n",
    "\n",
    "            target='diagnosis'\n",
    "            y_train=train[target]\n",
    "            y_test=test[target]\n",
    "            y_train=y_train.astype('int')\n",
    "            y_test=y_test.astype('int')\n",
    "            train.drop(columns=target,axis=1,inplace=True)\n",
    "            test.drop(columns=target,axis=1,inplace=True)\n",
    "            x_train=train\n",
    "            x_test=test\n",
    "\n",
    "\n",
    "            x_train=np.array(x_train)\n",
    "            x_test=np.array(x_test)\n",
    "            y_train=np.array(y_train)\n",
    "            y_test=np.array(y_test)\n",
    "\n",
    "\n",
    "\n",
    "            batch = 10\n",
    "\n",
    "            w,bias,nll=mini_batch_desc(x_train,y_train,batch)\n",
    "\n",
    "            y_predict=predict(x_test,w,bias,threshold)\n",
    "\n",
    "            x_points=range(1,len(nll)+1)\n",
    "            s=\"Mini Batch Gradient Lr = \"+ str(lr) + \" Threshold = \" + str(threshold)\n",
    "            plt.plot(x_points,nll)\n",
    "            plt.xlabel('Iterations', fontsize=20)\n",
    "            plt.ylabel('NLL ', fontsize=20)\n",
    "            plt.title(s)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            confusion, accuracy, precision, recall= confusion_matrix(y_predict,y_test)\n",
    "            print(\"CONFUSION MATRIX \\n\")\n",
    "            print(confusion)\n",
    "            print(\"ACCURACY =\", accuracy)\n",
    "            print(\"PRECISION =\", precision)\n",
    "            print(\"RECALL =\", recall)\n",
    "            print(\"\")\n",
    "            \n",
    "            l16[itr].append(accuracy)\n",
    "            l17[itr].append(precision)\n",
    "            l18[itr].append(recall)            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d665257e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEARNING RATE = 0.01, THRESHOLD = 0.5\n",
      "BATCH GRADIENT DESCENT\n",
      "LR1\n",
      "Accuracy\n",
      "Average =  0.5763440860215054 Standard Deviation =  0.17821262865050122\n",
      "Precision\n",
      "Average =  0.7458907294391166 Standard Deviation =  0.31128216099489203\n",
      "Recall\n",
      "Average =  0.5396602967368972 Standard Deviation =  0.39119858661610574\n",
      "LR2\n",
      "Accuracy\n",
      "Average =  0.9590425531914895 Standard Deviation =  0.012372024840013833\n",
      "Precision\n",
      "Average =  0.9487424772768062 Standard Deviation =  0.013953432487262272\n",
      "Recall\n",
      "Average =  0.9386084551602998 Standard Deviation =  0.026615303607714334\n",
      "STOCHASTIC GRADIENT DESCENT\n",
      "LR1\n",
      "Accuracy\n",
      "Average =  0.8349462365591398 Standard Deviation =  0.06460790962689322\n",
      "Precision\n",
      "Average =  0.7774850747464171 Standard Deviation =  0.16188651462324855\n",
      "Recall\n",
      "Average =  0.8794254190447062 Standard Deviation =  0.13402404380875763\n",
      "LR2\n",
      "Accuracy\n",
      "Average =  0.9393617021276597 Standard Deviation =  0.012406280627330424\n",
      "Precision\n",
      "Average =  1.0 Standard Deviation =  0.0\n",
      "Recall\n",
      "Average =  0.8325692731556942 Standard Deviation =  0.039517369058554366\n",
      "MINI BATCH GRADIENT DESCENT\n",
      "LR1\n",
      "Accuracy\n",
      "Average =  0.8623655913978494 Standard Deviation =  0.04473686895207466\n",
      "Precision\n",
      "Average =  0.7908524555507701 Standard Deviation =  0.12324952986857828\n",
      "Recall\n",
      "Average =  0.9003454932901848 Standard Deviation =  0.072502037008662\n",
      "LR2\n",
      "Accuracy\n",
      "Average =  0.9686170212765959 Standard Deviation =  0.008393475445776323\n",
      "Precision\n",
      "Average =  0.992274523539737 Standard Deviation =  0.007780490700404329\n",
      "Recall\n",
      "Average =  0.9201412900703569 Standard Deviation =  0.02607976198504841\n"
     ]
    }
   ],
   "source": [
    "print(\"LEARNING RATE = 0.01, THRESHOLD = 0.5\")\n",
    "\n",
    "print(\"BATCH GRADIENT DESCENT\")\n",
    "\n",
    "print(\"LR1\")\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(\"Average = \", np.average(np.array(l1)),\"Standard Deviation = \",np.std(np.array(l1)))\n",
    "print(\"Precision\")\n",
    "print(\"Average = \", np.average(np.array(l2)),\"Standard Deviation = \",np.std(np.array(l2)))\n",
    "print(\"Recall\")\n",
    "print(\"Average = \", np.average(np.array(l3)),\"Standard Deviation = \",np.std(np.array(l3)))\n",
    "\n",
    "print(\"LR2\")\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(\"Average = \", np.average(np.array(l4)),\"Standard Deviation = \",np.std(np.array(l4)))\n",
    "print(\"Precision\")\n",
    "print(\"Average = \", np.average(np.array(l5)),\"Standard Deviation = \",np.std(np.array(l5)))\n",
    "print(\"Recall\")\n",
    "print(\"Average = \", np.average(np.array(l6)),\"Standard Deviation = \",np.std(np.array(l6)))\n",
    "\n",
    "print(\"STOCHASTIC GRADIENT DESCENT\")\n",
    "\n",
    "print(\"LR1\")\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(\"Average = \", np.average(np.array(l7)),\"Standard Deviation = \",np.std(np.array(l7)))\n",
    "print(\"Precision\")\n",
    "print(\"Average = \", np.average(np.array(l8)),\"Standard Deviation = \",np.std(np.array(l8)))\n",
    "print(\"Recall\")\n",
    "print(\"Average = \", np.average(np.array(l9)),\"Standard Deviation = \",np.std(np.array(l9)))\n",
    "\n",
    "\n",
    "print(\"LR2\")\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(\"Average = \", np.average(np.array(l10)),\"Standard Deviation = \",np.std(np.array(l10)))\n",
    "print(\"Precision\")\n",
    "print(\"Average = \", np.average(np.array(l11)),\"Standard Deviation = \",np.std(np.array(l11)))\n",
    "print(\"Recall\")\n",
    "print(\"Average = \", np.average(np.array(l12)),\"Standard Deviation = \",np.std(np.array(l12)))\n",
    "\n",
    "\n",
    "print(\"MINI BATCH GRADIENT DESCENT\")\n",
    "\n",
    "print(\"LR1\")\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(\"Average = \", np.average(np.array(l13)),\"Standard Deviation = \",np.std(np.array(l13)))\n",
    "print(\"Precision\")\n",
    "print(\"Average = \", np.average(np.array(l14)),\"Standard Deviation = \",np.std(np.array(l14)))\n",
    "print(\"Recall\")\n",
    "print(\"Average = \", np.average(np.array(l15)),\"Standard Deviation = \",np.std(np.array(l15)))\n",
    "\n",
    "print(\"LR2\")\n",
    "\n",
    "print(\"Accuracy\")\n",
    "print(\"Average = \", np.average(np.array(l16)),\"Standard Deviation = \",np.std(np.array(l16)))\n",
    "print(\"Precision\")\n",
    "print(\"Average = \", np.average(np.array(l17)),\"Standard Deviation = \",np.std(np.array(l17)))\n",
    "print(\"Recall\")\n",
    "print(\"Average = \", np.average(np.array(l18)),\"Standard Deviation = \",np.std(np.array(l18)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
