{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76a1df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "accuracy_avg1=precision_avg1=recall_avg1=accuracy_avg2=precision_avg2=recall_avg2=accuracy_avg3=precision_avg3=recall_avg3=accuracy_avg4=precision_avg4=recall_avg4=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cb3d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_fit(x_train,y_train,x_test,y_test):\n",
    "    w=np.ones(30) #coefficient matric of out hyperplane\n",
    "\n",
    "    epoch=1000\n",
    "    tp=tn=fp=fn=0\n",
    "    \n",
    "    for i in range(epoch):\n",
    "    \n",
    "        for j in range(len(x_train)):\n",
    "            if (sum((w*x_train[j]))*y_train[j])<0:\n",
    "                w=w+(x_train[j])*y_train[j]\n",
    "\n",
    "    success=failure=0\n",
    "\n",
    "    for k in range(len(x_test)):\n",
    "        p=sum(w*x_test[k])\n",
    "        \n",
    "        \n",
    "        if p > 0 and y_test[k]>0:\n",
    "            tp+=1\n",
    "        elif p<0 and y_test[k]<0:\n",
    "            tn+=1\n",
    "        elif p>0 and y_test[k]<0:\n",
    "            fp+=1\n",
    "        else:\n",
    "            fn+=1\n",
    "            \n",
    "        \n",
    "        if p*y_test[k]>0:\n",
    "            success+=1\n",
    "        else:\n",
    "            failure+=1  \n",
    "    accuracy = (tp+tn)/(len(x_test))\n",
    "    precision=tp/(tp+fp)\n",
    "    recall=tp/(tp+fn)\n",
    "    \n",
    "    return accuracy, precision, recall\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1fc4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_1=[]\n",
    "l1_2=[]\n",
    "l1_3=[]\n",
    "l2_1=[]\n",
    "l2_2=[]\n",
    "l2_3=[]\n",
    "l3_1=[]\n",
    "l3_2=[]\n",
    "l3_3=[]\n",
    "l4_1=[]\n",
    "l4_2=[]\n",
    "l4_3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efc2d0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 1\n",
      "ACCURACY =  0.8870967741935484 PRECISION =  0.9130434782608695 RECALL =  0.9051724137931034\n",
      "ACCURACY =  0.8817204301075269 PRECISION =  0.8405797101449275 RECALL =  1.0\n",
      "ACCURACY =  0.9361702127659575 PRECISION =  0.9411764705882353 RECALL =  0.9572649572649573\n",
      "ACCURACY =  0.9361702127659575 PRECISION =  0.9411764705882353 RECALL =  0.9572649572649573\n",
      "ITERATION 2\n",
      "ACCURACY =  0.7688172043010753 PRECISION =  0.7189542483660131 RECALL =  1.0\n",
      "ACCURACY =  0.8924731182795699 PRECISION =  0.9166666666666666 RECALL =  0.9\n",
      "ACCURACY =  0.9680851063829787 PRECISION =  0.9818181818181818 RECALL =  0.9642857142857143\n",
      "ACCURACY =  0.9680851063829787 PRECISION =  0.9818181818181818 RECALL =  0.9642857142857143\n",
      "ITERATION 3\n",
      "ACCURACY =  0.8924731182795699 PRECISION =  0.8702290076335878 RECALL =  0.9743589743589743\n",
      "ACCURACY =  0.8440860215053764 PRECISION =  0.9888888888888889 RECALL =  0.7606837606837606\n",
      "ACCURACY =  0.925531914893617 PRECISION =  0.9338842975206612 RECALL =  0.9495798319327731\n",
      "ACCURACY =  0.925531914893617 PRECISION =  0.9338842975206612 RECALL =  0.9495798319327731\n",
      "ITERATION 4\n",
      "ACCURACY =  0.9139784946236559 PRECISION =  0.8790322580645161 RECALL =  0.990909090909091\n",
      "ACCURACY =  0.9354838709677419 PRECISION =  0.9083333333333333 RECALL =  0.990909090909091\n",
      "ACCURACY =  0.9574468085106383 PRECISION =  0.9642857142857143 RECALL =  0.9642857142857143\n",
      "ACCURACY =  0.9574468085106383 PRECISION =  0.9642857142857143 RECALL =  0.9642857142857143\n",
      "ITERATION 5\n",
      "ACCURACY =  0.9032258064516129 PRECISION =  0.875 RECALL =  0.9824561403508771\n",
      "ACCURACY =  0.9032258064516129 PRECISION =  0.9210526315789473 RECALL =  0.9210526315789473\n",
      "ACCURACY =  0.9574468085106383 PRECISION =  0.9652173913043478 RECALL =  0.9652173913043478\n",
      "ACCURACY =  0.9574468085106383 PRECISION =  0.9652173913043478 RECALL =  0.9652173913043478\n",
      "ITERATION 6\n",
      "ACCURACY =  0.9032258064516129 PRECISION =  0.8731343283582089 RECALL =  0.9915254237288136\n",
      "ACCURACY =  0.8548387096774194 PRECISION =  0.8137931034482758 RECALL =  1.0\n",
      "ACCURACY =  0.9680851063829787 PRECISION =  0.9523809523809523 RECALL =  1.0\n",
      "ACCURACY =  0.9680851063829787 PRECISION =  0.9523809523809523 RECALL =  1.0\n",
      "ITERATION 7\n",
      "ACCURACY =  0.8387096774193549 PRECISION =  0.7916666666666666 RECALL =  1.0\n",
      "ACCURACY =  0.9193548387096774 PRECISION =  0.9304347826086956 RECALL =  0.9385964912280702\n",
      "ACCURACY =  0.9574468085106383 PRECISION =  0.9652173913043478 RECALL =  0.9652173913043478\n",
      "ACCURACY =  0.9574468085106383 PRECISION =  0.9652173913043478 RECALL =  0.9652173913043478\n",
      "ITERATION 8\n",
      "ACCURACY =  0.9301075268817204 PRECISION =  0.9159663865546218 RECALL =  0.9732142857142857\n",
      "ACCURACY =  0.7150537634408602 PRECISION =  1.0 RECALL =  0.5267857142857143\n",
      "ACCURACY =  0.9414893617021277 PRECISION =  0.9473684210526315 RECALL =  0.9557522123893806\n",
      "ACCURACY =  0.9414893617021277 PRECISION =  0.9473684210526315 RECALL =  0.9557522123893806\n",
      "ITERATION 9\n",
      "ACCURACY =  0.8978494623655914 PRECISION =  0.8602941176470589 RECALL =  1.0\n",
      "ACCURACY =  0.8763440860215054 PRECISION =  0.8405797101449275 RECALL =  0.9914529914529915\n",
      "ACCURACY =  0.9414893617021277 PRECISION =  0.9572649572649573 RECALL =  0.9491525423728814\n",
      "ACCURACY =  0.9414893617021277 PRECISION =  0.9572649572649573 RECALL =  0.9491525423728814\n",
      "ITERATION 10\n",
      "ACCURACY =  0.8118279569892473 PRECISION =  0.9878048780487805 RECALL =  0.7043478260869566\n",
      "ACCURACY =  0.9301075268817204 PRECISION =  0.9396551724137931 RECALL =  0.9478260869565217\n",
      "ACCURACY =  0.9468085106382979 PRECISION =  0.9655172413793104 RECALL =  0.9491525423728814\n",
      "ACCURACY =  0.9468085106382979 PRECISION =  0.9655172413793104 RECALL =  0.9491525423728814\n",
      "---------------------------------\n",
      "PM1\n",
      "AVERAGE ACCURACY 0.8747311827956988\n",
      "AVERAGE PRECISION 0.8685125369600323\n",
      "AVERAGE RECALL 0.9521984154942101\n",
      "PM2\n",
      "AVERAGE ACCURACY 0.875268817204301\n",
      "AVERAGE PRECISION 0.9099983999228456\n",
      "AVERAGE RECALL 0.8977306767095097\n",
      "PM3\n",
      "AVERAGE ACCURACY 0.95\n",
      "AVERAGE PRECISION 0.9574131018899339\n",
      "AVERAGE RECALL 0.9619908297512998\n",
      "PM4\n",
      "AVERAGE ACCURACY 0.95\n",
      "AVERAGE PRECISION 0.9574131018899339\n",
      "AVERAGE RECALL 0.9619908297512998\n"
     ]
    }
   ],
   "source": [
    "for itr in range(10):\n",
    "    \n",
    "    print(\"ITERATION\", itr+1)\n",
    "\n",
    "    working_directory = os.getcwd()\n",
    "    path = working_directory + '/Dataset1.csv'   ##initialising path to data file, rename to fit in with your pc\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df.drop(columns='id',axis=1,inplace=True)  #dropping column id as it might give incorrect correlations\n",
    "\n",
    "    df = df.sample(frac=1) #shuffles the data\n",
    "    df2=df #PM2\n",
    "    df3=df #PM3\n",
    "    df4=df #PM4\n",
    "    \n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    for col in df.columns:    \n",
    "        if col== 'diagnosis':\n",
    "            df.loc[df[col]== 'M',col]= -1 #benign =1 ,malignant-=1\n",
    "            df.loc[df[col]== 'B',col] = 1\n",
    "    \n",
    "\n",
    "    ratio = 0.67\n",
    "    total_rows = df.shape[0]\n",
    "    train_size = int(total_rows*ratio)\n",
    "    train = df[0:train_size]\n",
    "    test = df[train_size:]\n",
    "\n",
    "    #PM1\n",
    "\n",
    "    target='diagnosis'\n",
    "    y_train=train[target]\n",
    "    y_test=test[target]\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "    train.drop(columns=target,axis=1,inplace= True)\n",
    "    test.drop(columns=target,axis=1, inplace=True)\n",
    "    x_train=train\n",
    "    x_test=test\n",
    "\n",
    "\n",
    "    x_train=np.array(x_train)\n",
    "    x_test=np.array(x_test)\n",
    "    y_train=np.array(y_train)\n",
    "    y_test=np.array(y_test)\n",
    "\n",
    "    accuracy,precision, recall = perceptron_fit(x_train,y_train,x_test,y_test)\n",
    "    accuracy_avg1 += (accuracy/10)\n",
    "    l1_1.append(accuracy)\n",
    "    precision_avg1 += (precision/10)\n",
    "    l1_2.append(precision)\n",
    "    recall_avg1 += (recall/10)   \n",
    "    l1_3.append(recall)\n",
    "    \n",
    "    print(\"ACCURACY = \", accuracy, \"PRECISION = \", precision,\"RECALL = \", recall)\n",
    "\n",
    "\n",
    "    \"\"\"__________________\"\"\"\n",
    "\n",
    "\n",
    "    #PM2\n",
    "    df2 = df2.dropna()\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    for col in df2.columns:    \n",
    "        if col== 'diagnosis':\n",
    "\n",
    "            df2.loc[df2[col]== 'M',col]= -1 #benign =1 ,malignant-=1\n",
    "            df2.loc[df2[col]== 'B',col] = 1\n",
    "\n",
    "    ratio = 0.67\n",
    "    total_rows = df2.shape[0]\n",
    "    train_size = int(total_rows*ratio)\n",
    "    train = df2[0:train_size]\n",
    "    test = df2[train_size:]\n",
    "\n",
    "\n",
    "    train = train.sample(frac=1)  #shuffles the training data\n",
    "\n",
    "\n",
    "    target='diagnosis'\n",
    "    y_train=train[target]\n",
    "    y_test=test[target]\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "    train.drop(columns=target,axis=1,inplace= True)\n",
    "    test.drop(columns=target,axis=1, inplace=True)\n",
    "    x_train=train\n",
    "    x_test=test\n",
    "\n",
    "\n",
    "    x_train=np.array(x_train)\n",
    "    x_test=np.array(x_test)\n",
    "    y_train=np.array(y_train)\n",
    "    y_test=np.array(y_test)\n",
    "\n",
    "    accuracy,precision, recall = perceptron_fit(x_train,y_train,x_test,y_test)\n",
    "    \n",
    "    accuracy_avg2 += (accuracy/10)\n",
    "    precision_avg2+= (precision/10)\n",
    "    recall_avg2+= (recall/10)\n",
    "    l2_1.append(accuracy)\n",
    "    l2_2.append(precision)\n",
    "    l2_3.append(recall)\n",
    "    \n",
    "    print(\"ACCURACY = \", accuracy, \"PRECISION = \", precision,\"RECALL = \", recall)\n",
    "\n",
    "    \"\"\"______________\"\"\"\n",
    "\n",
    "\n",
    "    #PM3\n",
    "\n",
    "\n",
    "    for col in df3.columns:    #filling in the missing values with the mean of that column\n",
    "        if col!= 'diagnosis':\n",
    "            mean=df3[col].mean()\n",
    "            df3[col] = df3[col].fillna(mean)\n",
    "        else:\n",
    "            df3.loc[df3[col]== 'M',col]= -1 #benign =1 ,malignant-=1\n",
    "            df3.loc[df3[col]== 'B',col] = 1\n",
    "\n",
    "    for column in df3.columns:   #normalization\n",
    "        if column != 'id' and column!= 'diagnosis':\n",
    "            df3[column] = (df3[column] - df3[column].mean()) / df3[column].std()  \n",
    "\n",
    "\n",
    "    ratio = 0.67\n",
    "    total_rows = df3.shape[0]\n",
    "    train_size = int(total_rows*ratio)\n",
    "    train = df3[0:train_size]\n",
    "    test = df3[train_size:]\n",
    "\n",
    "\n",
    "    target='diagnosis'\n",
    "    y_train=train[target]\n",
    "    y_test=test[target]\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "    train.drop(columns=target,axis=1,inplace= True)\n",
    "    test.drop(columns=target,axis=1, inplace=True)\n",
    "    x_train=train\n",
    "    x_test=test\n",
    "\n",
    "\n",
    "    x_train=np.array(x_train)\n",
    "    x_test=np.array(x_test)\n",
    "    y_train=np.array(y_train)\n",
    "    y_test=np.array(y_test)\n",
    "\n",
    "    accuracy,precision, recall = perceptron_fit(x_train,y_train,x_test,y_test)\n",
    "    accuracy_avg3 += (accuracy/10)\n",
    "    precision_avg3+= (precision/10)\n",
    "    recall_avg3 += (recall/10)\n",
    "    l3_1.append(accuracy)\n",
    "    l3_2.append(precision)\n",
    "    l3_3.append(recall)\n",
    "    \n",
    "    \n",
    "    print(\"ACCURACY = \", accuracy, \"PRECISION = \", precision,\"RECALL = \", recall)\n",
    "\n",
    "    \"\"\"______________\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    #PM4\n",
    "\n",
    "\n",
    "    df4=df4.sample(frac=1, axis=1)\n",
    "\n",
    "    for col in df4.columns:    #filling in the missing values with the mean of that column\n",
    "        if col!= 'diagnosis':\n",
    "            mean=df4[col].mean()\n",
    "            df4[col] = df4[col].fillna(mean)\n",
    "        else:\n",
    "            df4.loc[df4[col]== 'M',col]= -1 #benign =1 ,malignant-=1\n",
    "            df4.loc[df4[col]== 'B',col] = 1\n",
    "\n",
    "\n",
    "    ratio = 0.67\n",
    "    total_rows = df4.shape[0]\n",
    "    train_size = int(total_rows*ratio)\n",
    "    train = df4[0:train_size]\n",
    "    test = df4[train_size:]\n",
    "\n",
    "\n",
    "\n",
    "    target='diagnosis'\n",
    "    y_train=train[target]\n",
    "    y_test=test[target]\n",
    "    y_train=y_train.astype('int')\n",
    "    y_test=y_test.astype('int')\n",
    "    train.drop(columns=target,axis=1,inplace= True)\n",
    "    test.drop(columns=target,axis=1, inplace=True)\n",
    "    x_train=train\n",
    "    x_test=test\n",
    "\n",
    "\n",
    "    x_train=np.array(x_train)\n",
    "    x_test=np.array(x_test)\n",
    "    y_train=np.array(y_train)\n",
    "    y_test=np.array(y_test)\n",
    "\n",
    "    accuracy,precision, recall = perceptron_fit(x_train,y_train,x_test,y_test)\n",
    "    accuracy_avg4 += (accuracy/10)\n",
    "    precision_avg4+= (precision/10)\n",
    "    recall_avg4 += (recall/10)    \n",
    "    l4_1.append(accuracy)\n",
    "    l4_2.append(precision)\n",
    "    l4_3.append(recall)\n",
    "    \n",
    "    \n",
    "    print(\"ACCURACY = \", accuracy, \"PRECISION = \", precision,\"RECALL = \", recall)\n",
    "    \n",
    "print(\"---------------------------------\")\n",
    "print(\"PM1\")\n",
    "print (\"AVERAGE ACCURACY\", accuracy_avg1)\n",
    "print(\"AVERAGE PRECISION\", precision_avg1)\n",
    "print(\"AVERAGE RECALL\",recall_avg1)\n",
    "\n",
    "print(\"PM2\")\n",
    "print (\"AVERAGE ACCURACY\", accuracy_avg2)\n",
    "print(\"AVERAGE PRECISION\", precision_avg2)\n",
    "print(\"AVERAGE RECALL\",recall_avg2)\n",
    "\n",
    "print(\"PM3\")\n",
    "print (\"AVERAGE ACCURACY\", accuracy_avg3)\n",
    "print(\"AVERAGE PRECISION\", precision_avg3)\n",
    "print(\"AVERAGE RECALL\",recall_avg3)\n",
    "\n",
    "print(\"PM4\")\n",
    "print (\"AVERAGE ACCURACY\", accuracy_avg4)\n",
    "print(\"AVERAGE PRECISION\", precision_avg4)\n",
    "print(\"AVERAGE RECALL\",recall_avg4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0b68528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM1\n",
      "ACCURACY STD:  0.04868783483298249\n",
      "PRECISION STD:  0.06854422370802069\n",
      "RECALL STD:  0.08682727163793431\n",
      "PM2\n",
      "ACCURACY STD:  0.060626474662410515\n",
      "PRECISION STD:  0.05889309762099318\n",
      "RECALL STD:  0.1412426170803929\n",
      "PM3\n",
      "ACCURACY STD:  0.013287229783826392\n",
      "PRECISION STD:  0.013318425547138336\n",
      "RECALL STD:  0.014216123739533505\n",
      "PM4\n",
      "ACCURACY STD:  0.013287229783826392\n",
      "PRECISION STD:  0.013318425547138336\n",
      "RECALL STD:  0.014216123739533505\n"
     ]
    }
   ],
   "source": [
    "l1_1=np.array(l1_1)\n",
    "l1_2=np.array(l1_2)\n",
    "l1_3=np.array(l1_3)\n",
    "\n",
    "std_1_1=np.std(l1_1,axis=0)\n",
    "std_1_2=np.std(l1_2,axis=0)\n",
    "std_1_3=np.std(l1_3,axis=0)\n",
    "\n",
    "print(\"PM1\")\n",
    "print(\"ACCURACY STD: \",std_1_1)\n",
    "print(\"PRECISION STD: \",std_1_2)\n",
    "print(\"RECALL STD: \",std_1_3)\n",
    "\n",
    "l2_1=np.array(l2_1)\n",
    "l2_2=np.array(l2_2)\n",
    "l2_3=np.array(l2_3)\n",
    "\n",
    "std_2_1=np.std(l2_1,axis=0)\n",
    "std_2_2=np.std(l2_2,axis=0)\n",
    "std_2_3=np.std(l2_3,axis=0)\n",
    "\n",
    "print(\"PM2\")\n",
    "print(\"ACCURACY STD: \",std_2_1)\n",
    "print(\"PRECISION STD: \",std_2_2)\n",
    "print(\"RECALL STD: \",std_2_3)\n",
    "\n",
    "l3_1=np.array(l3_1)\n",
    "l3_2=np.array(l3_2)\n",
    "l3_3=np.array(l3_3)\n",
    "\n",
    "std_3_1=np.std(l3_1,axis=0)\n",
    "std_3_2=np.std(l3_2,axis=0)\n",
    "std_3_3=np.std(l3_3,axis=0)\n",
    "\n",
    "print(\"PM3\")\n",
    "print(\"ACCURACY STD: \",std_3_1)\n",
    "print(\"PRECISION STD: \",std_3_2)\n",
    "print(\"RECALL STD: \",std_3_3)\n",
    "\n",
    "l4_1=np.array(l4_1)\n",
    "l4_2=np.array(l4_2)\n",
    "l4_3=np.array(l4_3)\n",
    "\n",
    "std_4_1=np.std(l4_1,axis=0)\n",
    "std_4_2=np.std(l4_2,axis=0)\n",
    "std_4_3=np.std(l4_3,axis=0)\n",
    "\n",
    "print(\"PM4\")\n",
    "print(\"ACCURACY STD: \",std_4_1)\n",
    "print(\"PRECISION STD: \",std_4_2)\n",
    "print(\"RECALL STD: \",std_4_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28fb812",
   "metadata": {},
   "source": [
    "# Q-LT1) The only difference between PM1 and PM2 is that we are shuffling the rows (using .sample) so the row split for train, test between the two is different therefore giving slightly altered values for average accuracy, precision and recall between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75369bea",
   "metadata": {},
   "source": [
    "# Q-LT2) The only differences between PM1 and PM3 is that we are normalizing the data in PM3 while that in PM1 isn't, also in PM1 we drop the rows which have NaN values while in PM3 we replace it with mean of the respective feature. As is expected the average accuracy, precision and recall values increase in PM3 after normalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed3719",
   "metadata": {},
   "source": [
    "# Q-LT3) Between PM3 and PM4 we are only shuffling the columns which obviously doesn't affect the metrics we are measuring in any way, which can be seen from the fact that average readings of PM3 and PM4 are the same, because in either case , all the columns are iterated through. Given this the only actual difference between PM1 and PM4 which causes any measurable change is the fact that we are normalising the data in PM4 and while in PM4 we use mean values instead of NaN in PM1 we remove the said row."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
